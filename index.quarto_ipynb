{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"thesctrading\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    df-print: paged\n",
        "\n",
        "jupyter: py312env\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## S&C Trading Strategy Overview\n",
        "\n",
        "### 1. Strategy Outline\n",
        "\n",
        "Our team is implementing a buy low / sell high strategy focused on short-term momentum trading in TSLA stock. We aim to take advantage of periods of elevated volatility and momentum, holding positions for 10 trading days or less. We use the 10 day window to account for the fact that some of our data sources are weekly and may provide more signal over a longer trade horizon. Of course, if the system hits its limit point during the window, the position will close similar to our HW1 model.\n",
        "\n",
        "*note that we plan to use backward elimination ML method to determine most important features. We plan to trial a variety of alternative data features from FRED (detailed at the end of the website) as well as some competitor company technical factors. **We also wish to include valuation metrics using the yfinance package.***\n",
        "\n",
        "#### Example Trade Walkthrough\n",
        "\n",
        "Pre-Trade Filter\n",
        "\n",
        "1. Check if job postings for software roles increased week-over-week\n",
        "   (as well as other FRED/alternative data including pairs performance)\n",
        "2. Check if implied volatility (IV) percentile > 50% and < 90%\n",
        "3. If both are true â†’ proceed to trade evaluation\n",
        "\n",
        "---\n",
        "\n",
        "Buy Conditions\n",
        "\n",
        "1. Price is above the 50-day SMA (or EMA)\n",
        "   *note we may also include valuation metrics here to avoid extreme overvaluation given our long-only strategy*\n",
        "2. Gamma exposure is positive\n",
        "   (or some other Greek we can calculate)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Exit Strategy\n",
        "\n",
        "We use four exit triggers to manage risk and lock in profits:\n",
        "\n",
        "1. If position is open for more than 10 trading days, exit regardless of performance\n",
        "2. If IV percentile drops below 30%, exit\n",
        "3. Exit if price reaches a profit target of 2x last week's average true range (ATR)\n",
        "4. Use a trailing stop loss of 1.5x ATR below the highest price reached since entry\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Position Sizing Framework\n",
        "\n",
        "Position size will adapt based on strength of indicators and perhaps on a regression of additional features not used to determine the weekly position strategy similar to the logistic regression model used in HW1. We envision a less binary model where sizing is continuous determined on a variety of features (allows us to take risk off but also keep risk on more granularly than the original model).\n",
        "\n",
        "Conditions for each tier will be finalized after further backtesting.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Data Requirements\n",
        "\n",
        "We plan to collect and process:\n",
        "\n",
        "- Price data and technical indicators (SMA, ATR, IV, Options contracts)\n",
        "- Job posting data & other relevant metrics from FRED\n",
        "- Automotive industry data from FRED\n",
        "- Implied volatility percentile data (via IBKR)\n",
        "\n",
        "We may use the FRED API, yFinance, or custom scrapers to automate data gathering.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Next Steps\n",
        "\n",
        "- Gather full feature list and find good alt data and implement backward elimination model to decide useful features\n",
        "- Build & backtest position sizing model\n",
        "- Backtest the strategy on historical TSLA data\n",
        "- Deploy the final version to https://thesctrading.com\n",
        "\n",
        "### 6. Practice Data Table"
      ],
      "id": "6f062644"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import Markdown\n",
        "from tabulate import tabulate\n",
        "table = [[\"Sun\",\"696,000\",1.989e30],\n",
        "         [\"Earth\",\"6,371\",5.972e24],\n",
        "         [\"Moon\",\"1,737\",7.34e22],\n",
        "         [\"Mars\",\"3,390\",6.39e23]]\n",
        "Markdown(tabulate(\n",
        "  table,\n",
        "  headers=[\"Astronomical object\",\"R (km)\", \"mass (kg)\"]\n",
        "))"
      ],
      "id": "4a9ab49a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Practice Image\n",
        "\n",
        "![Practice Elephant from Quarto Guide](elephant.png)\n",
        "\n",
        "### 8. FRED Data: Software Developer Job Postings\n",
        "\n",
        "The below is demonstrating our ability to use the FRED API to pull in features. This example is weekly software job postings. We plan to scour FRED to identify other features that may be useful. Other things may include potential regulatory items or things indicating sentiment on Elon as well as other automotive industry stats including production, CPI, etc. We plan to test a variety and perhaps identify the most powerful features through supervised feature selection methods. Likely **backward selection** where the model evaluates all the features and removes the least powerful/most noisy one by one."
      ],
      "id": "550209bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from fredapi import Fred\n",
        "\n",
        "# Connect to FRED\n",
        "fred = Fred(api_key=\"1c00931ee7dc4304c6bb68b72fb2d68f\")\n",
        "\n",
        "# Fetch data\n",
        "series_id = \"IHLIDXUSTPSOFTDEVE\"\n",
        "data = fred.get_series(series_id)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"Job Postings\"])\n",
        "df.index.name = \"Date\"\n",
        "df = df.reset_index()\n",
        "\n",
        "# Display last 5 rows as table\n",
        "df.tail()"
      ],
      "id": "eb787c21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot the time series\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(df[\"Date\"], df[\"Job Postings\"], linewidth=2)\n",
        "plt.title(\"US Software Developer Job Postings Index\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Index Value\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "27ed3804",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Blotter & Ledger Code\n"
      ],
      "id": "cbb80a61"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shinybroker as sb\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm"
      ],
      "id": "4cc8a845",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetch data"
      ],
      "id": "5a62cf10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "asset= sb.Contract({\n",
        "    'symbol': \"ARES\",\n",
        "    'secType': \"STK\",\n",
        "    'exchange': \"SMART\",\n",
        "    'currency': \"USD\"\n",
        "})\n",
        "\n",
        "benchmark = sb.Contract({\n",
        "    'symbol': \"SPX\",\n",
        "    'secType': \"IND\",\n",
        "    'exchange': \"CBOE\",\n",
        "    'currency': \"USD\"\n",
        "})\n",
        "\n",
        "#### Get hourly data to use for calculating vol\n",
        "historical_data_hourly_fetch = sb.fetch_historical_data(\n",
        "    contract=asset,\n",
        "    endDateTime='',         # Let IBKR set the \"now\" time\n",
        "    durationStr='1 Y',      # Past 1 year\n",
        "    barSizeSetting='1 hour', # Daily bars\n",
        "    whatToShow='TRADES',\n",
        "    useRTH=True,\n",
        "    #date_format=1,          # String time zone date\n",
        "    #keepUpToDate=False\n",
        ")\n",
        "historical_data_hourly = historical_data_hourly_fetch['hst_dta']\n",
        "\n",
        "#### Get daily data as well because it speeds up the code\n",
        "####   writing process.\n",
        "historical_data_daily_fetch = sb.fetch_historical_data(\n",
        "    contract=asset,\n",
        "    endDateTime='',         # Let IBKR set the \"now\" time\n",
        "    durationStr='1 Y',      # Past 1 year\n",
        "    barSizeSetting='1 day', # Daily bars\n",
        "    whatToShow='TRADES',\n",
        "    useRTH=True,\n",
        "    #date_format=1,          # String time zone date\n",
        "    #keepUpToDate=False\n",
        ")\n",
        "historical_data_daily = historical_data_daily_fetch['hst_dta']\n",
        "# print(\"HDD\", historical_data_daily)\n",
        "\n",
        "#### Fetch your liquid trading hours for the asset\n",
        "#### You'll need this later!\n",
        "ares_deets = sb.fetch_contract_details(\n",
        "    contract=sb.Contract({\n",
        "        'symbol': \"ARES\",\n",
        "        'secType': \"STK\",\n",
        "        'exchange': \"SMART\",\n",
        "        'currency': \"USD\"\n",
        "    })\n",
        ")\n",
        "liquid_hours = ares_deets['liquidHours']\n",
        "# print(liquid_hours)\n",
        "#liquid_hours = (ares_deets['liquidHours'][0])\n",
        "\n",
        "def safe_fetch_iv(contract, durationStr, barSizeSetting, label):\n",
        "    try:\n",
        "        fetch = sb.fetch_historical_data(\n",
        "            contract=contract,\n",
        "            endDateTime='',\n",
        "            durationStr=durationStr,\n",
        "            barSizeSetting=barSizeSetting,\n",
        "            whatToShow='OPTION_IMPLIED_VOLATILITY',\n",
        "            useRTH=True,\n",
        "        )\n",
        "        df = fetch['hst_dta']\n",
        "        print(f\"{label} IV data fetched. Rows: {len(df)}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"{label} IV fetch failed: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Replace your fetch calls with:\n",
        "#iv_historical_data_hourly = safe_fetch_iv(\n",
        "#    contract=asset,\n",
        "#    durationStr='1 Y',\n",
        "#    barSizeSetting='1 hour',\n",
        "#    label=\"Hourly\"\n",
        "#)\n",
        "\n",
        "iv_historical_data_daily = safe_fetch_iv(\n",
        "    contract=asset,\n",
        "    durationStr='1 Y',\n",
        "    barSizeSetting='1 day',\n",
        "    label=\"Daily\"\n",
        ")\n",
        "\n",
        "# Optional: preview what was fetched\n",
        "# print(iv_historical_data_daily.head())\n",
        "\n",
        "\n",
        "historical_data_daily_fetch_SMA = sb.fetch_historical_data(\n",
        "    contract=asset,\n",
        "    endDateTime='',         # Let IBKR set the \"now\" time\n",
        "    durationStr='2 Y',      # Past 1 year\n",
        "    barSizeSetting='1 day', # Daily bars\n",
        "    whatToShow='TRADES',\n",
        "    useRTH=True,\n",
        "    #date_format=1,          # String time zone date\n",
        "    #keepUpToDate=False\n",
        ")\n",
        "historical_data_daily_SMA = historical_data_daily_fetch_SMA['hst_dta']#%% md"
      ],
      "id": "a591e93a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean Data"
      ],
      "id": "4204b95d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Make sure 'date' is a datetime column\n",
        "historical_data_daily_SMA['timestamp'] = pd.to_datetime(historical_data_daily_SMA['timestamp'])\n",
        "\n",
        "# Sort by date just to be safe\n",
        "historical_data_daily_SMA = historical_data_daily_SMA.sort_values('timestamp')\n",
        "\n",
        "# Calculate 20-day simple moving average\n",
        "historical_data_daily_SMA['SMA_20'] = historical_data_daily_SMA['close'].rolling(window=20).mean()\n",
        "\n",
        "print(historical_data_daily_SMA['SMA_20'])\n",
        "\n",
        "#### Prepare Data\n",
        "# Function to calculate trade period\n",
        "def get_trade_period(dt):\n",
        "    iso_year, iso_week, _ = dt.isocalendar()\n",
        "    return float(f\"{iso_year}.{iso_week:02d}\")\n",
        "\n",
        "# Ensure 'date' column is in datetime format\n",
        "historical_data_daily['timestamp'] = pd.to_datetime(historical_data_daily['timestamp'])\n",
        "historical_data_hourly['timestamp'] = pd.to_datetime(historical_data_hourly['timestamp'])\n",
        "iv_historical_data_daily['timestamp'] = pd.to_datetime(iv_historical_data_daily['timestamp'])\n",
        "#iv_historical_data_hourly['timestamp'] = pd.to_datetime(iv_historical_data_hourly['timestamp'])\n",
        "#liquid_hours['timestamp'] = pd.to_datetime(liquid_hours['timestamp'])\n",
        "\n",
        "# Apply trade period calculation\n",
        "historical_data_daily['trd_prd'] = historical_data_daily['timestamp'].apply(get_trade_period)\n",
        "historical_data_hourly['trd_prd'] = historical_data_hourly['timestamp'].apply(get_trade_period)\n",
        "iv_historical_data_daily['trd_prd'] = iv_historical_data_daily['timestamp'].apply(get_trade_period)\n",
        "#iv_historical_data_hourly['trd_prd'] = iv_historical_data_hourly['timestamp'].apply(get_trade_period)\n",
        "historical_data_daily_SMA['trd_prd'] = historical_data_daily_SMA['timestamp'].apply(get_trade_period)\n",
        "\n",
        "#liquid_hours['trd_prd'] = liquid_hours['timestamp'].apply(get_trade_period)\n",
        "\n",
        "# Identify the first full five-trading-day week\n",
        "weekly_counts = historical_data_daily.groupby('trd_prd')['timestamp'].count()\n",
        "first_full_week = weekly_counts[weekly_counts >= 5].index.min()\n",
        "\n",
        "# Filter historical_data_daily\n",
        "historical_data_daily = historical_data_daily[historical_data_daily['trd_prd'] >= first_full_week]"
      ],
      "id": "2b800aca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print DFs"
      ],
      "id": "8b7b19a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Print dataframes\n",
        "print(\"Historical Data Daily:\")\n",
        "print(historical_data_daily)\n",
        "\n",
        "print(\"\\nHistorical Data Hourly:\")\n",
        "print(historical_data_hourly)\n",
        "\n",
        "print(\"IV Historical Data Daily:\")\n",
        "print(iv_historical_data_daily)\n",
        "\n",
        "#print(\"\\n IV Historical Data Hourly:\")\n",
        "#print(iv_historical_data_daily)\n",
        "\n",
        "print(\"Historical SMA Data Daily:\")\n",
        "print(historical_data_daily_SMA)\n",
        "\n",
        "print(\"\\nLiquid Hours:\")\n",
        "print(liquid_hours)"
      ],
      "id": "f6a710c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vol"
      ],
      "id": "479c82ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calc Obs & Exp Vol\n",
        "# Extract trade periods from daily historical data\n",
        "trade_periods = historical_data_daily['trd_prd'].unique()\n",
        "\n",
        "# Calculate observed volatility using hourly data\n",
        "hourly_log_returns = np.log(historical_data_hourly['close'] / historical_data_hourly['close'].shift(1))\n",
        "hourly_vols = hourly_log_returns.groupby(historical_data_hourly['timestamp'].dt.strftime('%Y-%W')).std()\n",
        "\n",
        "# Convert hourly vol to weekly vol (scale by sqrt(32.5))\n",
        "weekly_vols = hourly_vols * np.sqrt(32.5)\n",
        "\n",
        "# Create DataFrame\n",
        "vol_calcs = pd.DataFrame(index=trade_periods, columns=['obs_vol', 'exp_vol'])\n",
        "vol_calcs['obs_vol'] = weekly_vols.values[:len(trade_periods)]\n",
        "\n",
        "# Set expected vol (shifted obs_vol)\n",
        "vol_calcs['exp_vol'] = vol_calcs['obs_vol'].shift(1)\n",
        "\n",
        "# Display the DataFrame\n",
        "# print(\"\\nVolatility Calculations:\")\n",
        "# print(vol_calcs)\n",
        "\n",
        "# Calc Obs & Exp Vol\n",
        "# Extract trade periods from daily historical data\n",
        "trade_periods = historical_data_daily['trd_prd'].unique()\n",
        "\n",
        "# Calculate observed volatility using hourly data\n",
        "hourly_log_returns = np.log(historical_data_hourly['close'] / historical_data_hourly['close'].shift(1))\n",
        "hourly_vols = hourly_log_returns.groupby(historical_data_hourly['timestamp'].dt.strftime('%Y-%W')).std()\n",
        "\n",
        "# Convert hourly vol to weekly vol (scale by sqrt(32.5))\n",
        "weekly_vols = hourly_vols * np.sqrt(32.5)\n",
        "\n",
        "# Create DataFrame\n",
        "smart_vol_calcs = pd.DataFrame(index=trade_periods, columns=['obs_vol', 'exp_vol'])\n",
        "smart_vol_calcs['obs_vol'] = weekly_vols.values[:len(trade_periods)]\n",
        "\n",
        "# Set expected vol (from options IV)\n",
        "for trd_prd in smart_vol_calcs.index:\n",
        "    smart_vol_calcs.at[trd_prd, 'exp_vol'] = iv_historical_data_daily.loc[\n",
        "        iv_historical_data_daily['trd_prd'] == trd_prd, 'open'\n",
        "    ].iloc[0] * np.sqrt(1/52)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"\\nVolatility Calculations:\")\n",
        "print(smart_vol_calcs)\n",
        "vol_calcs = smart_vol_calcs\n",
        "\n",
        "#vol_calcs = smart_vol_calcs # manually toggle active vol calc"
      ],
      "id": "365c7702",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Blotter & Ledger"
      ],
      "id": "6b2d6576"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract trade periods from daily historical data\n",
        "trade_periods = historical_data_daily['trd_prd'].unique()\n",
        "\n",
        "# Calc blotter\n",
        "blotter = pd.DataFrame(index=trade_periods[1:], columns=['entry_timestamp', 'qty', 'exit_timestamp', 'entry_price', 'exit_price', 'success', 'iv', 'wap', 'sma'])\n",
        "blotter[:] = None  # Set empty values\n",
        "\n",
        "# Initialize Ledger\n",
        "filtered_historical = historical_data_daily[historical_data_daily['trd_prd'] != historical_data_daily['trd_prd'].iloc[0]]\n",
        "ledger = pd.DataFrame()\n",
        "ledger['date'] = filtered_historical['timestamp']\n",
        "ledger['position'] = 0.0  # Placeholder values\n",
        "ledger['cash'] = 0.0  # Placeholder values\n",
        "ledger['mark'] = historical_data_daily['close'][1:]\n",
        "ledger['mkt_value'] = 0.0  # Placeholder values\n",
        "#ledger['cash'] = 50000\n",
        "\n",
        "print(\"\\nLedger:\")\n",
        "print(ledger)\n",
        "\n",
        "# Blotter & Ledger Loop\n",
        "# This is where \"backtesting\" really occurs. We're calculating the blotter &\n",
        "# ledger that our trading system WOULD have produced.\n",
        "for trd_prd in blotter.index:\n",
        "    entry_timestamp = historical_data_hourly.loc[historical_data_hourly['trd_prd'] == trd_prd, 'timestamp'].iloc[0]\n",
        "    entry_price = historical_data_hourly.loc[historical_data_hourly['trd_prd'] == trd_prd, 'open'].iloc[0]\n",
        "    prev_close = historical_data_daily.loc[historical_data_daily['trd_prd'] < trd_prd, 'close'].iloc[-1]\n",
        "    exp_vol = vol_calcs.loc[trd_prd, 'exp_vol']\n",
        "    iv = iv_historical_data_daily.loc[iv_historical_data_daily['trd_prd'] == trd_prd, 'wap'].iloc[0]\n",
        "    wap = historical_data_hourly.loc[historical_data_hourly['trd_prd'] == trd_prd, 'wap'].iloc[0]\n",
        "    sma = historical_data_daily_SMA.loc[historical_data_daily_SMA['trd_prd'] == trd_prd, 'SMA_20'].iloc[0]\n",
        "\n",
        "    if entry_price > prev_close:\n",
        "        qty = -100\n",
        "        exit_price_strategy = entry_price * (1 - exp_vol)\n",
        "    else:\n",
        "        qty = 100\n",
        "        exit_price_strategy = entry_price * (1 + exp_vol)\n",
        "\n",
        "    period_data = historical_data_hourly[historical_data_hourly['trd_prd'] == trd_prd]\n",
        "    max_high = period_data['high'].max()\n",
        "    min_low = period_data['low'].min()\n",
        "\n",
        "    if (qty > 0 and max_high >= exit_price_strategy) or (qty < 0 and min_low <= exit_price_strategy):\n",
        "        success = True\n",
        "        exit_price = exit_price_strategy\n",
        "\n",
        "        if qty > 0:\n",
        "            exit_timestamp = period_data.loc[period_data['high'] >= exit_price_strategy, 'timestamp'].iloc[0]\n",
        "            exit_high_price = period_data.loc[period_data['high'] >= exit_price_strategy, 'high'].iloc[0]\n",
        "            exit_low_price = period_data.loc[period_data['high'] >= exit_price_strategy, 'low'].iloc[0]\n",
        "        else:\n",
        "            exit_timestamp = period_data.loc[period_data['low'] <= exit_price_strategy, 'timestamp'].iloc[0]\n",
        "            exit_high_price = period_data.loc[period_data['low'] <= exit_price_strategy, 'high'].iloc[0]\n",
        "            exit_low_price = period_data.loc[period_data['low'] <= exit_price_strategy, 'low'].iloc[0]\n",
        "\n",
        "        #print(exit_low_price, exit_high_price, exit_price_strategy, exit_timestamp, qty)\n",
        "    else:\n",
        "        success = False\n",
        "        exit_price = historical_data_daily.loc[historical_data_daily['trd_prd'] == trd_prd, 'close'].iloc[-1]\n",
        "        #exit_timestamp = historical_data_daily.loc[historical_data_daily['trd_prd'] == trd_prd, 'timestamp'].iloc[-1]\n",
        "        exit_timestamp = pd.to_datetime(\n",
        "        historical_data_daily.loc[historical_data_daily['trd_prd'] == trd_prd, 'timestamp'].iloc[-1]).replace(hour=15, minute=0, second=0)\n",
        "\n",
        "\n",
        "    blotter.loc[trd_prd] = [entry_timestamp, qty, exit_timestamp, entry_price, exit_price, success, iv, wap, sma]\n",
        "\n",
        "    ledger.loc[ledger['date'] >= entry_timestamp, 'position'] += qty\n",
        "    ledger.loc[ledger['date'] >= exit_timestamp, 'position'] -= qty\n",
        "    ledger.loc[ledger['date'] >= entry_timestamp, 'cash'] -= qty * entry_price\n",
        "    ledger.loc[ledger['date'] >= exit_timestamp, 'cash'] += qty * exit_price\n",
        "\n",
        "# finally, calculate your strategy's end-of-day mark-to-market value\n",
        "ledger['mkt_value'] = ledger['position'] * ledger['mark'] + ledger['cash']"
      ],
      "id": "98f5db6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extra"
      ],
      "id": "ee79cd6c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = blotter[['iv', 'wap', 'sma']]\n",
        "y = blotter['success'].astype(int)\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(y.value_counts())\n",
        "\n",
        "\n",
        "# Fit model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "# y_pred = model.predict(X_test) # 0.5 threshold\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (probs > 0.3).astype(int)\n",
        "\n",
        "fill = len(y_train)\n",
        "padded_y_pred = np.concatenate(([1.0] * fill, y_pred))\n",
        "blotter['prediction'] = pd.Series(padded_y_pred, index=blotter.index)\n",
        "\n",
        "# Results\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Blotter\", blotter)"
      ],
      "id": "6ee38e9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Outputting Interactive Blotter & Ledger"
      ],
      "id": "4ae5f2df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your final blotter DataFrame already populated at this point\n",
        "blotter = blotter.round(3)  # Optional: round for cleaner display"
      ],
      "id": "29a04b7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display blotter as interactive table\n",
        "from itables import show\n",
        "show(blotter)"
      ],
      "id": "fbb8cb54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your final ledger DataFrame already populated at this point\n",
        "ledger = ledger.round(2)  # Optional: clean output"
      ],
      "id": "51e3c2d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display ledger as interactive table\n",
        "show(ledger)"
      ],
      "id": "c4ec3ac1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NAV/Charts & Extra (not necessary)"
      ],
      "id": "9cf09bc2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create an empty list to store categories\n",
        "position_category = []\n",
        "\n",
        "# Categorize positions manually\n",
        "for pos in ledger['position']:\n",
        "    if pos > 0:\n",
        "        position_category.append('Long')\n",
        "    elif pos < 0:\n",
        "        position_category.append('Short')\n",
        "    else:\n",
        "        position_category.append('Cash Only')\n",
        "\n",
        "# Add category column to ledger\n",
        "ledger['position_category'] = position_category\n",
        "\n",
        "# Define colors for each category\n",
        "color_map = {'Long': 'green', 'Short': 'red', 'Cash Only': 'blue'}\n",
        "colors = []\n",
        "\n",
        "# Assign colors manually\n",
        "for cat in ledger['position_category']:\n",
        "    colors.append(color_map[cat])\n",
        "\n",
        "# Plot NAV over time\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(ledger['date'], ledger['mkt_value'], c=colors, alpha=0.7)\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Net Asset Value (NAV)')\n",
        "plt.title('NAV Over Time with Position Coloring, Standard Model')\n",
        "plt.grid(True)\n",
        "\n",
        "# Manually add legend\n",
        "for cat, color in color_map.items():\n",
        "    plt.scatter([], [], color=color, label=cat)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Initialize Ledger\n",
        "filtered_historical = historical_data_daily[historical_data_daily['trd_prd'] != historical_data_daily['trd_prd'].iloc[0]]\n",
        "new_ledger = pd.DataFrame()\n",
        "new_ledger['date'] = filtered_historical['timestamp']\n",
        "new_ledger['position'] = 0.0  # Placeholder values\n",
        "new_ledger['cash'] = 0.0  # Placeholder values\n",
        "new_ledger['mark'] = historical_data_daily['close'][1:]\n",
        "new_ledger['mkt_value'] = 0.0  # Placeholder values\n",
        "#new_ledger['cash'] = 50000\n",
        "\n",
        "for trd_prd in blotter.index:\n",
        "    if blotter.loc[trd_prd]['prediction'] == 0: # if the trade is predicted to fail, no trade\n",
        "        qty = 0\n",
        "    else: # if in train set or predicted success, make the trade\n",
        "        qty = blotter.loc[trd_prd, 'qty']\n",
        "\n",
        "    entry_price = blotter.loc[trd_prd]['entry_price']\n",
        "    entry_timestamp = blotter.loc[trd_prd]['entry_timestamp']\n",
        "    exit_timestamp = blotter.loc[trd_prd]['exit_timestamp']\n",
        "    exit_price = blotter.loc[trd_prd]['exit_price']\n",
        "\n",
        "    new_ledger.loc[new_ledger['date'] >= entry_timestamp, 'position'] += qty\n",
        "    new_ledger.loc[new_ledger['date'] >= exit_timestamp, 'position'] -= qty\n",
        "    new_ledger.loc[new_ledger['date'] >= entry_timestamp, 'cash'] -= qty * entry_price\n",
        "    new_ledger.loc[new_ledger['date'] >= exit_timestamp, 'cash'] += qty * exit_price\n",
        "\n",
        "# finally, calculate your strategy's end-of-day mark-to-market value\n",
        "new_ledger['mkt_value'] = new_ledger['position'] * new_ledger['mark'] + new_ledger['cash']\n",
        "print(new_ledger)\n",
        "\n",
        "# Create an empty list to store categories\n",
        "position_category = []\n",
        "\n",
        "# Categorize positions manually\n",
        "for pos in new_ledger['position']:\n",
        "    if pos > 0:\n",
        "        position_category.append('Long')\n",
        "    elif pos < 0:\n",
        "        position_category.append('Short')\n",
        "    else:\n",
        "        position_category.append('Cash Only')\n",
        "\n",
        "# Add category column to new_ledger\n",
        "new_ledger['position_category'] = position_category\n",
        "\n",
        "# Define colors for each category\n",
        "color_map = {'Long': 'green', 'Short': 'red', 'Cash Only': 'blue'}\n",
        "colors = []\n",
        "\n",
        "# Assign colors manually\n",
        "for cat in new_ledger['position_category']:\n",
        "    colors.append(color_map[cat])\n",
        "\n",
        "# Plot NAV over time\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(new_ledger['date'], new_ledger['mkt_value'], c=colors, alpha=0.7)\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Net Asset Value (NAV)')\n",
        "plt.title('NAV Over Time with Position Coloring, Enhanced Model')\n",
        "plt.grid(True)\n",
        "\n",
        "# Manually add legend\n",
        "for cat, color in color_map.items():\n",
        "    plt.scatter([], [], color=color, label=cat)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "blotter['return'] = ((blotter['exit_price'] - blotter['entry_price']) / blotter['entry_price']) * (blotter['qty'] / abs(blotter['qty'])) # get returns irrespective of long/short\n",
        "\n",
        "#print(\"\\nExit Timestamps:\")\n",
        "#print(blotter['exit_timestamp'])\n",
        "\n",
        "# Fetch entry and exit prices from historical_data_hourly based on timestamps\n",
        "blotter['entry_price_underlying'] = blotter['entry_timestamp'].apply(\n",
        "    lambda ts: historical_data_hourly.loc[historical_data_hourly['timestamp'] == ts, 'close'].iloc[0]\n",
        ")\n",
        "\n",
        "blotter['exit_price_underlying'] = blotter.apply(\n",
        "    lambda row: (\n",
        "        historical_data_hourly.loc[historical_data_hourly['timestamp'] == row['exit_timestamp'], 'close'].iloc[0]\n",
        "        if not historical_data_hourly.loc[historical_data_hourly['timestamp'] == row['exit_timestamp'], 'close'].empty\n",
        "        else (\n",
        "            historical_data_daily.loc[historical_data_daily['timestamp'] == row['exit_timestamp'], 'close'].iloc[0]\n",
        "            if not historical_data_daily.loc[historical_data_daily['timestamp'] == row['exit_timestamp'], 'close'].empty\n",
        "            else None  # If neither dataset has the timestamp\n",
        "        )\n",
        "    ), axis=1\n",
        ")\n",
        "\n",
        "# Calculate return based on hourly data\n",
        "blotter['return_underlying'] = (blotter['exit_price_underlying'] - blotter['entry_price_underlying']) / blotter['entry_price_underlying']* (blotter['qty'] / abs(blotter['qty']))\n",
        "\n",
        "x = pd.to_numeric(blotter['return_underlying'])\n",
        "original_index = x.index.copy()\n",
        "x.dropna(inplace=True)\n",
        "dropped_rows = original_index.difference(x.index)\n",
        "y = pd.to_numeric(blotter['return'])\n",
        "y.drop(index=dropped_rows, inplace=True)\n",
        "\n",
        "# Scatter plot of returns\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x, y, alpha=0.6, label=\"Trades\")\n",
        "plt.xlabel(\"Underlying Return\")\n",
        "plt.ylabel(\"Strategy Return\")\n",
        "plt.title(\"Strategy Return vs. Underlying Return, Standard Model\")\n",
        "\n",
        "#print(x,y)\n",
        "\n",
        "# Fit a linear regression model to get alpha and beta\n",
        "x_with_const = sm.add_constant(x)  # Adds intercept for regression\n",
        "model = sm.OLS(y, x_with_const).fit()\n",
        "alpha, beta = model.params\n",
        "\n",
        "# Plot regression line\n",
        "plt.plot(x, alpha + beta * x, color='red', label=f\"Regression Line (Î±={alpha:.4f}, Î²={beta:.4f})\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print alpha and beta values\n",
        "\n",
        "alpha, beta\n",
        "\n",
        "blotter['return'] = ((blotter['exit_price'] - blotter['entry_price']) / blotter['entry_price']) * (blotter['qty'] / abs(blotter['qty'])) * blotter['prediction']# get returns irrespective of long/short\n",
        "\n",
        "#print(\"\\nExit Timestamps:\")\n",
        "#print(blotter['exit_timestamp'])\n",
        "\n",
        "# Fetch entry and exit prices from historical_data_hourly based on timestamps\n",
        "blotter['entry_price_underlying'] = blotter['entry_timestamp'].apply(\n",
        "    lambda ts: historical_data_hourly.loc[historical_data_hourly['timestamp'] == ts, 'close'].iloc[0]\n",
        ")\n",
        "\n",
        "blotter['exit_price_underlying'] = blotter.apply(\n",
        "    lambda row: (\n",
        "        historical_data_hourly.loc[historical_data_hourly['timestamp'] == row['exit_timestamp'], 'close'].iloc[0]\n",
        "        if not historical_data_hourly.loc[historical_data_hourly['timestamp'] == row['exit_timestamp'], 'close'].empty\n",
        "        else (\n",
        "            historical_data_daily.loc[historical_data_daily['timestamp'] == row['exit_timestamp'], 'close'].iloc[0]\n",
        "            if not historical_data_daily.loc[historical_data_daily['timestamp'] == row['exit_timestamp'], 'close'].empty\n",
        "            else None  # If neither dataset has the timestamp\n",
        "        )\n",
        "    ), axis=1\n",
        ")\n",
        "\n",
        "# Calculate return based on hourly data\n",
        "blotter['return_underlying'] = (blotter['exit_price_underlying'] - blotter['entry_price_underlying']) / blotter['entry_price_underlying']* (blotter['qty'] / abs(blotter['qty']))\n",
        "\n",
        "x = pd.to_numeric(blotter['return_underlying'])\n",
        "original_index = x.index.copy()\n",
        "x.dropna(inplace=True)\n",
        "dropped_rows = original_index.difference(x.index)\n",
        "y = pd.to_numeric(blotter['return'])\n",
        "y.drop(index=dropped_rows, inplace=True)\n",
        "\n",
        "# Scatter plot of returns\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x, y, alpha=0.6, label=\"Trades\")\n",
        "plt.xlabel(\"Underlying Return\")\n",
        "plt.ylabel(\"Strategy Return\")\n",
        "plt.title(\"Strategy Return vs. Underlying Return, Enhanced Model\")\n",
        "\n",
        "#print(x,y)\n",
        "\n",
        "# Fit a linear regression model to get alpha and beta\n",
        "x_with_const = sm.add_constant(x)  # Adds intercept for regression\n",
        "model = sm.OLS(y, x_with_const).fit()\n",
        "alpha, beta = model.params\n",
        "\n",
        "# Plot regression line\n",
        "plt.plot(x, alpha + beta * x, color='red', label=f\"Regression Line (Î±={alpha:.4f}, Î²={beta:.4f})\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print alpha and beta values\n",
        "\n",
        "alpha, beta"
      ],
      "id": "fef0c2ba",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "py312env",
      "language": "python",
      "display_name": "Python 3.12 (conda)",
      "path": "/Users/samfuller/Library/Jupyter/kernels/py312env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}